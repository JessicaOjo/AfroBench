<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AfroBench</title>
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-900 text-white font-sans">
    
    <!-- Navigation Bar -->
    <nav class="flex justify-between items-center p-6 bg-gray-800 shadow-md">
        <h1 class="text-2xl font-bold">AfroBench</h1>
        <ul class="flex space-x-6">
            <li><a href="leaderboard.html" class="hover:text-yellow-400">Leaderboard</a></li>
            <li><a href="codebase.html" class="hover:text-yellow-400">Codebase</a></li>
            <li><a href="data.html" class="hover:text-yellow-400">Data</a></li>
            <li><a href="https://arxiv.org/abs/PAPER_LINK" class="hover:text-yellow-400">Paper</a></li>
        </ul>
    </nav>
    
    <!-- Hero Section -->
    <header class="text-center mt-16">
        <h1 class="text-5xl font-extrabold">Benchmarking LLMs for African Languages</h1>
        <p class="mt-4 text-gray-400 text-lg">Evaluating 64 African languages across 15 NLP tasks.</p>
    </header>
    
    <!-- Overview Section -->
    <section class="mt-12 max-w-4xl mx-auto text-center">
        <p class="text-lg">AfroBench is a comprehensive benchmark for evaluating large language models (LLMs) on African languages, covering translation, question answering, text classification, and more.</p>
        <p class="text-lg font-bold text-yellow-400 mt-4">Check out the <a href="https://arxiv.org/abs/PAPER_LINK" class="underline">paper</a> for more details and visit the <a href="leaderboard.html" class="underline">leaderboard</a> for detailed results!</p>
    </section>
 
    <!-- Call to Action -->
    <section class="text-center mt-12">
        <a href="leaderboard.html" class="px-6 py-3 bg-yellow-500 rounded-full text-lg font-bold shadow-md hover:bg-yellow-400">View Leaderboard</a>
        <a href="https://github.com/JessicaOjo/AfroBench" class="ml-4 px-6 py-3 bg-blue-500 rounded-full text-lg font-bold shadow-md hover:bg-blue-400">GitHub Repo</a>
    </section>

    <!-- Key Highlights -->
    <section class="mt-12 grid grid-cols-1 md:grid-cols-3 gap-6 max-w-5xl mx-auto text-center">
        <div class="p-6 bg-gray-800 rounded-lg shadow-lg">
            <h2 class="text-2xl font-bold">64 Languages</h2>
            <p class="text-gray-400 mt-2">Evaluating diverse African languages for NLP fairness.</p>
        </div>
        <div class="p-6 bg-gray-800 rounded-lg shadow-lg">
            <h2 class="text-2xl font-bold">15 Tasks</h2>
            <p class="text-gray-400 mt-2">From machine translation to sentiment analysis.</p>
        </div>
        <div class="p-6 bg-gray-800 rounded-lg shadow-lg">
            <h2 class="text-2xl font-bold">Open & Fair</h2>
            <p class="text-gray-400 mt-2">Built with lm-eval-harness for transparent benchmarking.</p>
        </div>
    </section>
    
    <!-- AfroBench Task Image -->
    <section class="mt-12 text-center">
        <img src="assets/afrobench-tasks.png" alt="AfroBench Tasks" class="mx-auto w-3/4 shadow-lg rounded-lg">
        <p class="text-gray-400 mt-4 text-sm">Figure: Overview of 15 NLP tasks and 22 datasets covered in AfroBench.</p>
    </section>
    
    <!-- Insights & Findings -->
    <section class="mt-12 max-w-5xl mx-auto text-left">
        <h2 class="text-3xl font-bold">Key Insights</h2>
        <ul class="mt-4 list-disc list-inside text-gray-400">
            <li>LLMs perform significantly better in high-resource languages compared to African languages.</li>
            <li>Proprietary models like GPT-4o and Gemini-1.5 outperform open-source models.</li>
            <li>Fine-tuned baselines on AfroBench datasets often achieve higher performance than prompted LLMs.</li>
            <li>Knowledge-intensive and reasoning tasks exhibit the largest performance gap.</li>
        </ul>
    </section>
        <!-- Evaluation Tables and Figures -->
        <section class="mt-12 text-center">
            <h2 class="text-3xl font-bold">Evaluation Results</h2>
            <img src="assets/afrobench-eval.png" alt="AfroBench Evaluation Results" class="mx-auto w-3/4 shadow-lg rounded-lg">
            <p class="text-gray-400 mt-4 text-sm">Table: AfroBench evaluation results for fine-tuned models and LLMs across tasks.</p>
<!--             <img src="assets/afrobench-lite.png" alt="AfroBench Lite" class="mx-auto w-3/4 shadow-lg rounded-lg mt-6">
            <p class="text-gray-400 mt-4 text-sm">Table: AfroBench-LITE results on selected tasks across African languages.</p> -->
            <img src="assets/afrobench-lang-perf.png" alt="AfroBench Language Performance" class="mx-auto w-3/4 shadow-lg rounded-lg mt-6">
            <p class="text-gray-400 mt-4 text-sm">Figure: AfroBench-LITE performance across languages and available monolingual data.</p>
        </section>
    

        <!-- Citation -->
        <section class="mt-12 max-w-5xl mx-auto text-left">
            <h2 class="text-3xl font-bold">Cite AfroBench</h2>
            <pre class="bg-gray-800 p-4 rounded-lg text-gray-400 text-sm overflow-x-auto">
    @article{AfroBench2024,
      author    = {Jessica Ojo and Odunayo Ogundepo and Akintunde Oladipo and Kelechi Ogueji et al.},
      title     = {AfroBench: Benchmarking Large Language Models on African Languages},
      year      = {2024},
      journal   = {Arxiv},
      url       = {arxiv link}
    }</pre>
        </section>

    
    <!-- Footer -->
    <footer class="text-center mt-12 py-6 text-gray-500 text-sm">Â© 2025 AfroBench - Evaluating AI for African Languages</footer>
    
</body>
</html>
