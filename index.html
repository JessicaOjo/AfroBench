<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AfroBench</title>
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="min-h-screen bg-gray-50">

    <!-- Navigation -->
    <nav class="sticky top-0 z-50 bg-white shadow-sm border-b border-gray-200">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex justify-between items-center h-16">
                <h1 class="text-2xl font-bold text-gray-900">AfroBench</h1>
                <ul class="flex space-x-8">
                    <li><a href="leaderboard.html" class="text-gray-600 hover:text-yellow-600 transition-colors">Leaderboard</a></li>
                    <li><a href="codebase.html" class="text-gray-600 hover:text-yellow-600 transition-colors">Codebase</a></li>
                    <li><a href="data.html" class="text-gray-600 hover:text-yellow-600 transition-colors">Data</a></li>
                    <li><a href="https://arxiv.org/abs/PAPER_LINK" class="text-gray-600 hover:text-yellow-600 transition-colors">Paper</a></li>
                </ul>
            </div>
        </div>
    </nav>

            <!-- Hero Section -->
<!--     <header class="relative bg-white overflow-hidden text-center py-20">
        <h1 class="text-4xl font-extrabold text-gray-900 sm:text-5xl md:text-6xl">
            <span class="block">Benchmarking LLMs for</span>
            <span class="block text-yellow-600">African Languages</span>
        </h1>
        <p class="mt-4 text-gray-500 text-lg max-w-xl mx-auto">
            Evaluating 64 African languages across 15 NLP tasks
        </p>
        <div class="mt-8 flex justify-center space-x-4">
            <a href="https://arxiv.org/abs/PAPER_LINK" class="px-8 py-3 bg-yellow-600 text-white font-medium rounded-md hover:bg-yellow-700">Read Paper</a>
            <a href="https://github.com/JessicaOjo/AfroBench" class="px-8 py-3 bg-yellow-100 text-yellow-700 font-medium rounded-md hover:bg-yellow-200">View GitHub</a>
        </div>
    </header> -->

    <!-- Hero Section -->
    <div class="relative bg-white overflow-hidden">
        <div class="max-w-7xl mx-auto">
            <div class="relative z-10 pb-8 bg-white sm:pb-16 md:pb-20 lg:w-full lg:pb-28 xl:pb-32">
                <main class="mt-10 mx-auto max-w-7xl px-4 sm:mt-12 sm:px-6 md:mt-16 lg:mt-20 lg:px-8 xl:mt-28">
                    <div class="text-center">
                        <h1 class="text-4xl tracking-tight font-extrabold text-gray-900 sm:text-5xl md:text-6xl">
                            <span class="block">Benchmarking LLMs for</span>
                            <span class="block text-yellow-600">African Languages</span>
                        </h1>
                        <p class="mt-3 text-base text-gray-500 sm:mt-5 sm:text-lg sm:max-w-xl sm:mx-auto md:mt-5 md:text-xl">
                            Evaluating 64 African languages across 15 NLP tasks
                        </p>
                        <div class="mt-5 sm:mt-8 sm:flex sm:justify-center">
                            <div class="rounded-md shadow">
                                <a href="https://arxiv.org/abs/PAPER_LINK" class="w-full flex items-center justify-center px-8 py-3 border border-transparent text-base font-medium rounded-md text-white bg-yellow-600 hover:bg-yellow-700 md:py-4 md:text-lg md:px-10">
                                    Read Paper
                                </a>
                            </div>
                            <div class="mt-3 sm:mt-0 sm:ml-3">
                                <a href="https://github.com/JessicaOjo/AfroBench" class="w-full flex items-center justify-center px-8 py-3 border border-transparent text-base font-medium rounded-md text-yellow-700 bg-yellow-100 hover:bg-yellow-200 md:py-4 md:text-lg md:px-10">
                                    View GitHub
                                </a>
                            </div>
                        </div>
                    </div>
                </main>
            </div>
        </div>
    </div>

    <!-- Abstract Section -->
    <section class="py-16 bg-gray-50">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="lg:text-center">
                <h2 class="text-3xl font-bold text-gray-900">Abstract</h2>
                <div class="mt-4 max-w-3xl mx-auto text-xl text-gray-500 leading-relaxed">
                    <p>
                        Large-scale multilingual evaluations, such as MEGA, often include only a handful of African languages due to the scarcity of high-quality evaluation data and the limited discoverability of existing African datasets. This lack of representation hinders comprehensive LLM evaluation across a diverse range of languages and tasks. To address these challenges, we introduce AFROBENCH—a multi-task benchmark for evaluating the performance of LLMs across 64 African languages, 15 tasks and 22 datasets. AFROBENCH consists of nine natural language understanding datasets, five text generation datasets, five knowledge and question answering tasks, and one mathematical reasoning task. We present results comparing the performance of prompting LLMs to fine-tuned baselines based on BERT and T5-style models. Our results suggest large gaps in performance between high-resource languages, such as English, and African languages across most tasks; but performance also varies based on the availability of monolingual data resources. Our findings confirm that performance on African languages continues to remain a hurdle for current LLMs, underscoring the need for additional efforts to close this gap.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Key Metrics Grid -->
    <section class="py-12 bg-white">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="grid grid-cols-1 gap-8 md:grid-cols-3">
                <div class="bg-yellow-50 rounded-xl p-8 text-center">
                    <div class="text-4xl font-bold text-yellow-600">64</div>
                    <div class="mt-2 text-gray-600">Languages Evaluated</div>
                </div>
                <div class="bg-yellow-50 rounded-xl p-8 text-center">
                    <div class="text-4xl font-bold text-yellow-600">15</div>
                    <div class="mt-2 text-gray-600">NLP Tasks</div>
                </div>
                <div class="bg-yellow-50 rounded-xl p-8 text-center">
                    <div class="text-4xl font-bold text-yellow-600">21+</div>
                    <div class="mt-2 text-gray-600">Datasets</div>
                </div>
            </div>
        </div>
    </section>


    <!-- Evaluation Tables and Figures -->
    <section class="mt-12 text-right">
        <h2 class="text-3xl font-bold">AfroBench Evaluation</h2>
        <p class="text-gray-700 mt-2">AFROBENCH is the first comprehensive LLM benchmark for African languages, evaluating proprietary and open models across 15 NLP tasks, 21 datasets, and 64 languages. Covering both Natural Language Understanding and Generation, it challenges models beyond traditional benchmarks with tasks like mathematical reasoning and knowledge QA. AFROBENCH provides critical insights into model performance across diverse linguistic landscapes. The results showcase the performance of various LLMs across different NLP tasks.</p>
        <img src="assets/afrobench-lang-perf.png" alt="AfroBench Language Performance" class="mx-auto w-3/4 shadow-lg rounded-lg mt-6">
        <p class="text-gray-400 mt-4 text-sm">Figure: AfroBench-LITE performance across languages and available monolingual data.</p>
    </section>

    <section class="mt-12 text-right">
        <h2 class="text-3xl font-bold">AfroBench-LITE Evaluation</h2>
        <div class="flex flex-col md:flex-row items-center md:items-start text-gray-700 mt-2">
            <p class="md:w-1/2">
                AFROBENCH-LITE is a streamlined version of AFROBENCH, designed for comprehensive LLM evaluation under compute constraints. 
                It establishes baselines across 7 datasets and 14 African languages, ensuring broad NLP coverage while maintaining language consistency. 
                Below, we compare AFROBENCH-LITE scores with the monolingual data size of each language based on MADLAD.
            </p>
            <img src="assets/afrobench-lite.png" alt="AfroBench Lite" class="md:w-1/2 shadow-lg rounded-lg ml-6">
        </div>
        <img src="assets/afrobench-lang-perf.png" alt="AfroBench Language Performance" class="mx-auto w-3/4 shadow-lg rounded-lg mt-6">
        <p class="text-gray-400 mt-4 text-sm">Figure: AfroBench-LITE performance across languages and available monolingual data.</p>
    </section>

    <!-- Citation -->
    <section class="mt-12 max-w-5xl mx-auto text-left bg-white p-6 rounded-lg shadow-lg border border-gray-200">
        <h2 class="text-3xl font-bold text-gray-900">Cite AfroBench</h2>
        <pre class="bg-gray-100 p-4 rounded-lg text-gray-800 text-sm overflow-x-auto border border-gray-300">
        @article{AfroBench2024,
          author    = {Jessica Ojo and Odunayo Ogundepo and Akintunde Oladipo and Kelechi Ogueji et al.},
          title     = {AfroBench: Benchmarking Large Language Models on African Languages},
          year      = {2024},
          journal   = {Arxiv},
          url       = {arxiv link}
        }</pre>
    </section>

    
    <!-- Footer -->
    <footer class="text-center mt-12 py-6 text-gray-500 text-sm">© 2025 AfroBench - Evaluating AI for African Languages</footer>
    
</body>
</html>
